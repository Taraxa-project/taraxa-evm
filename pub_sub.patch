Index: taraxa/util/concurrent/pub_sub/pub_sub.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- taraxa/util/concurrent/pub_sub/pub_sub.go	(date 1567534342172)
+++ taraxa/util/concurrent/pub_sub/pub_sub.go	(date 1567534342172)
@@ -0,0 +1,72 @@
+package pub_sub
+
+import (
+	"runtime"
+	"sync/atomic"
+	"unsafe"
+)
+
+type node struct {
+	prev        *node
+	value       interface{}
+	hasBeenRead uint32
+}
+
+type PubSub struct {
+	head unsafe.Pointer
+}
+
+func (this *PubSub) Write(value interface{}) bool {
+	// TODO swap-store
+	newNode := &node{value: value}
+	for {
+		headPtr := atomic.LoadPointer(&this.head)
+		if newNode.prev = (*node)(headPtr); newNode.prev != nil && newNode.prev.value == nil {
+			return false
+		}
+		if atomic.CompareAndSwapPointer(&this.head, headPtr, unsafe.Pointer(newNode)) {
+			return true
+		}
+	}
+}
+
+func (this *PubSub) RequestTermination() bool {
+	return this.Write(nil)
+}
+
+func (this *PubSub) NewReader() *Reader {
+	return &Reader{headPtr: &this.head}
+}
+
+type Reader struct {
+	headPtr           *unsafe.Pointer
+	prevHead          *node
+	toRead            *node
+	currentHead       *node
+	hasSeenTerminator bool
+}
+
+func (this *Reader) Read(unreadOnly bool) (val interface{}) {
+	for val == nil {
+		if this.toRead == this.prevHead {
+			if this.hasSeenTerminator {
+				return nil
+			}
+			this.prevHead = this.currentHead
+			for {
+				if this.toRead = (*node)(atomic.LoadPointer(this.headPtr)); this.toRead != this.currentHead {
+					this.currentHead = this.toRead
+					break
+				}
+				runtime.Gosched()
+			}
+		}
+		if val = this.toRead.value; val == nil {
+			this.hasSeenTerminator = true
+		} else if !atomic.CompareAndSwapUint32(&this.toRead.hasBeenRead, 0, 1) && unreadOnly {
+			val = nil
+		}
+		this.toRead = this.toRead.prev
+	}
+	return
+}
Index: taraxa/util/concurrent/pub_sub/pub_sub_test.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- taraxa/util/concurrent/pub_sub/pub_sub_test.go	(date 1567533123175)
+++ taraxa/util/concurrent/pub_sub/pub_sub_test.go	(date 1567533123175)
@@ -0,0 +1,121 @@
+package pub_sub
+
+import (
+	"github.com/Taraxa-project/taraxa-evm/taraxa/util"
+	"github.com/Taraxa-project/taraxa-evm/taraxa/util/benchmarking"
+	"github.com/Taraxa-project/taraxa-evm/taraxa/util/concurrent"
+	"sync/atomic"
+	"testing"
+)
+
+func BenchmarkSumN(b *testing.B) {
+	N := 100000
+	expectedSum := (N * (N + 1)) / 2
+	benchmarking.AddBenchmark(b, "pub_sub", func(b *testing.B, i int) {
+		var pubSub PubSub
+		reader := pubSub.NewReader()
+		quitChan := make(chan interface{})
+		go func() {
+			total := 0
+			for {
+				if val := reader.Read(false); val != nil {
+					total += val.(int)
+				} else {
+					break
+				}
+			}
+			util.Assert(total == expectedSum)
+			close(quitChan)
+		}()
+		concurrent.Parallelize(concurrent.CPU_COUNT, N, func(int) func(int) {
+			return func(i int) {
+				pubSub.Write(i + 1)
+			}
+		})
+		pubSub.RequestTermination()
+		<-quitChan
+	})
+	benchmarking.AddBenchmark(b, "chan", func(b *testing.B, i int) {
+		ch := make(chan interface{}, N)
+		quitChan := make(chan interface{})
+		go func() {
+			total := 0
+			for {
+				if val := <-ch; val != nil {
+					total += val.(int)
+				} else {
+					break
+				}
+			}
+			util.Assert(total == expectedSum)
+			close(quitChan)
+		}()
+		concurrent.Parallelize(concurrent.CPU_COUNT, N, func(int) func(int) {
+			return func(i int) {
+				ch <- i + 1
+			}
+		})
+		ch <- nil
+		<-quitChan
+	})
+}
+
+func BenchmarkSumNConcurrentReads(b *testing.B) {
+	N := 10000000
+	expectedSum := uint32((N * (N + 1)) / 2)
+	parallelism := concurrent.CPU_COUNT
+	benchmarking.AddBenchmark(b, "pub_sub", func(b *testing.B, i int) {
+		var pubSub PubSub
+		var total uint32
+		rendezvous := concurrent.NewRendezvous(parallelism)
+		for i := 0; i < parallelism; i++ {
+			go func() {
+				defer rendezvous.CheckIn()
+				reader := pubSub.NewReader()
+				for {
+					if val := reader.Read(true); val != nil {
+						atomic.AddUint32(&total, val.(uint32))
+					} else {
+						break
+					}
+				}
+			}()
+		}
+		concurrent.Parallelize(parallelism, N, func(int) func(int) {
+			return func(i int) {
+				pubSub.Write(uint32(i + 1))
+			}
+		})
+		pubSub.RequestTermination()
+		rendezvous.Await()
+		total = atomic.LoadUint32(&total)
+		util.Assert(total == expectedSum)
+	})
+	benchmarking.AddBenchmark(b, "chan", func(b *testing.B, i int) {
+		ch := make(chan interface{}, N)
+		var total uint32
+		rendezvous := concurrent.NewRendezvous(parallelism)
+		for i := 0; i < parallelism; i++ {
+			go func() {
+				defer rendezvous.CheckIn()
+				for {
+					if val, ok := <-ch; ok && val != nil {
+						atomic.AddUint32(&total, val.(uint32))
+					} else {
+						concurrent.TryClose(ch)
+						break
+					}
+				}
+			}()
+		}
+		concurrent.Parallelize(parallelism, N, func(int) func(int) {
+			return func(i int) {
+				ch <- uint32(i + 1)
+			}
+		})
+		ch <- nil
+		rendezvous.Await()
+		total = atomic.LoadUint32(&total)
+		util.Assert(total == expectedSum)
+	})
+}
